{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GADGETS.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNKQ8DeJSt4Ag6i91PEla9N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Lg3YoLrvXC-V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1593673814937,"user_tz":-330,"elapsed":4337,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"ea17dc58-e414-4b6f-892e-adf3b93b8fe1"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n","and then re-execute this cell.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kJqbYgezXHkF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1593745601745,"user_tz":-330,"elapsed":23647,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"b82838dd-c5e8-4032-ab6e-c4ca2144d05e"},"source":["from google.colab import drive\n","drive.mount('/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CZic6m32XHgO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745607307,"user_tz":-330,"elapsed":965,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["import os\n","os.chdir('/drive/My Drive')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"xz65XW4KXHc9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593744332110,"user_tz":-330,"elapsed":902,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["#pip install tensorflow==1.14.0"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkXegX0XpBTX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745619207,"user_tz":-330,"elapsed":1270,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":[""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"usa1Dmz7XHWl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745619214,"user_tz":-330,"elapsed":635,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["import warnings"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XQDVh7XXHTP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745621093,"user_tz":-330,"elapsed":1184,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"KB3zu4ilXHP2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745622513,"user_tz":-330,"elapsed":646,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["IMAGE_SIZE = [224, 224]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"WR_SSJlDXm_L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1593745634906,"user_tz":-330,"elapsed":11572,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"6a054939-1756-47b7-c7d7-6f15eb17df4b"},"source":["vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S6FPcRowXm6D","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745636944,"user_tz":-330,"elapsed":954,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["# don't train existing weights\n","for layer in vgg.layers:\n","  layer.trainable = False"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdrR1Aw4Xm3K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":857},"executionInfo":{"status":"ok","timestamp":1593745638338,"user_tz":-330,"elapsed":680,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"1b82d834-3ba4-4ba3-8e7b-4d2f9f1fe0fa"},"source":["x = Flatten()(vgg.output)\n","prediction = Dense(4, activation='softmax')(x)\n","model = Model(inputs=vgg.input, outputs=prediction)\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 100356    \n","=================================================================\n","Total params: 14,815,044\n","Trainable params: 100,356\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i-trvHegXm0O","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745639703,"user_tz":-330,"elapsed":641,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["from keras import optimizers\n","\n","\n","sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n","model.compile(loss='binary_crossentropy',\n","              optimizer=sgd,\n","              metrics=['accuracy'])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"GcMEDz4iXmxX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745641319,"user_tz":-330,"elapsed":731,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["# Data Augmentation\n","train_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOmXxYIjXmu0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593745642598,"user_tz":-330,"elapsed":657,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["# Data Augmentation\n","test_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"19ZHeiYLXmsb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593745646156,"user_tz":-330,"elapsed":2932,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"7f89d8e5-e91c-4a9a-8bc5-b30b20216ceb"},"source":["# Make sure you provide the same target size as initialied for the image size\n","train_set = train_datagen.flow_from_directory('/drive/My Drive/IMAGE_RECOGNITION/GADGETS/train',\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Found 264 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-IEusWKMXmp0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593745647837,"user_tz":-330,"elapsed":957,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"01834186-b251-45c2-e38a-93dca806179c"},"source":["test_set = test_datagen.flow_from_directory('/drive/My Drive/IMAGE_RECOGNITION/GADGETS/train',\n","                                            target_size = (224, 224),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Found 264 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"__6O7-aGXmmL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593751964938,"user_tz":-330,"elapsed":4728638,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"98cb1852-156c-4c99-f98a-0a67839bc2ee"},"source":["from datetime import datetime\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras.callbacks import ReduceLROnPlateau\n","\n","#lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)\n","\n","#num_epochs = 1000\n","#num_batch_size = 32\n","\n","checkpoint = ModelCheckpoint(filepath='/drive/My Drive/IMAGE_RECOGNITION/GADGETS/my_model.h5', \n","                               verbose=1, save_best_only=True)\n","\n","callbacks = [checkpoint, lr_reducer]\n","\n","start = datetime.now()\n","\n","model.fit_generator(\n","  train_set,\n","  validation_data=test_set,\n","  epochs=15,\n","  steps_per_epoch=500,\n","  validation_steps=15,\n","    callbacks=callbacks ,verbose=1)\n","\n","\n","duration = datetime.now() - start\n","print(\"Training completed in time: \", duration)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","  1/500 [..............................] - ETA: 8:02 - loss: 3.6045 - accuracy: 0.7656"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["500/500 [==============================] - 321s 641ms/step - loss: 3.4617 - accuracy: 0.7739 - val_loss: 1.6482 - val_accuracy: 0.8509\n","\n","Epoch 00001: val_loss improved from inf to 1.64822, saving model to /drive/My Drive/IMAGE_RECOGNITION/GADGETS/my_model.h5\n","Epoch 2/15\n","500/500 [==============================] - 320s 640ms/step - loss: 0.8539 - accuracy: 0.9441 - val_loss: 0.0000e+00 - val_accuracy: 0.9757\n","\n","Epoch 00002: val_loss improved from 1.64822 to -0.00000, saving model to /drive/My Drive/IMAGE_RECOGNITION/GADGETS/my_model.h5\n","Epoch 3/15\n","500/500 [==============================] - 314s 629ms/step - loss: 0.5390 - accuracy: 0.9651 - val_loss: 1.9171 - val_accuracy: 0.9560\n","\n","Epoch 00003: val_loss did not improve from -0.00000\n","Epoch 4/15\n","500/500 [==============================] - 320s 639ms/step - loss: 0.5533 - accuracy: 0.9635 - val_loss: 0.9586 - val_accuracy: 0.9682\n","\n","Epoch 00004: val_loss did not improve from -0.00000\n","Epoch 5/15\n","500/500 [==============================] - 320s 641ms/step - loss: 0.3571 - accuracy: 0.9765 - val_loss: 0.4721 - val_accuracy: 0.9734\n","\n","Epoch 00005: val_loss did not improve from -0.00000\n","Epoch 6/15\n","500/500 [==============================] - 319s 638ms/step - loss: 0.3259 - accuracy: 0.9783 - val_loss: 0.0000e+00 - val_accuracy: 0.9792\n","\n","Epoch 00006: val_loss did not improve from -0.00000\n","Epoch 7/15\n","500/500 [==============================] - 311s 622ms/step - loss: 0.3024 - accuracy: 0.9807 - val_loss: 0.3148 - val_accuracy: 0.9825\n","\n","Epoch 00007: val_loss did not improve from -0.00000\n","Epoch 8/15\n","500/500 [==============================] - 317s 633ms/step - loss: 0.2358 - accuracy: 0.9847 - val_loss: 0.0000e+00 - val_accuracy: 0.9919\n","\n","Epoch 00008: val_loss did not improve from -0.00000\n","Epoch 9/15\n","500/500 [==============================] - 313s 625ms/step - loss: 0.1803 - accuracy: 0.9880 - val_loss: 0.0000e+00 - val_accuracy: 0.9873\n","\n","Epoch 00009: val_loss did not improve from -0.00000\n","Epoch 10/15\n","500/500 [==============================] - 310s 619ms/step - loss: 0.1641 - accuracy: 0.9891 - val_loss: 0.0000e+00 - val_accuracy: 0.9912\n","\n","Epoch 00010: val_loss did not improve from -0.00000\n","Epoch 11/15\n","500/500 [==============================] - 315s 630ms/step - loss: 0.1867 - accuracy: 0.9881 - val_loss: 0.0000e+00 - val_accuracy: 0.9873\n","\n","Epoch 00011: val_loss did not improve from -0.00000\n","Epoch 12/15\n","500/500 [==============================] - 310s 619ms/step - loss: 0.1568 - accuracy: 0.9898 - val_loss: 0.0000e+00 - val_accuracy: 0.9919\n","\n","Epoch 00012: val_loss did not improve from -0.00000\n","Epoch 13/15\n","500/500 [==============================] - 312s 624ms/step - loss: 0.1493 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 0.9956\n","\n","Epoch 00013: val_loss did not improve from -0.00000\n","Epoch 14/15\n","500/500 [==============================] - 313s 625ms/step - loss: 0.1467 - accuracy: 0.9905 - val_loss: 0.2396 - val_accuracy: 0.9873\n","\n","Epoch 00014: val_loss did not improve from -0.00000\n","Epoch 15/15\n","500/500 [==============================] - 314s 628ms/step - loss: 0.1309 - accuracy: 0.9912 - val_loss: 0.0000e+00 - val_accuracy: 0.9884\n","\n","Epoch 00015: val_loss did not improve from -0.00000\n","Training completed in time:  1:18:47.773298\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qprDQEBUXmf8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593751997831,"user_tz":-330,"elapsed":2823,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["\n","from tensorflow import keras\n","model = keras.models.load_model('/drive/My Drive/IMAGE_RECOGNITION/GADGETS/my_model.h5',)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LXrQJ40PUT5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593752006084,"user_tz":-330,"elapsed":3343,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}}},"source":["# Part 3 - Making new predictions\n","import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('/drive/My Drive/IMAGE_RECOGNITION/GADGETS/test/watch/1.jpg', target_size = (224,224))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = model.predict(test_image)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZ7ZrwuVjtaP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593752008188,"user_tz":-330,"elapsed":942,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"1f6bbcc4-678a-4d9a-e7c7-2b7ac6cad816"},"source":["train_set.class_indices"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'backpack': 0, 'footwear': 1, 'glasses': 2, 'watch': 3}"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"zOf77P7SliAg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593752010943,"user_tz":-330,"elapsed":976,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"4e3b8ecd-351c-474b-8098-38c4757770e0"},"source":["result\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 1.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"6DTLxDBtkflE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593752012761,"user_tz":-330,"elapsed":999,"user":{"displayName":"anil kumar","photoUrl":"","userId":"02316193638766718211"}},"outputId":"2d153347-5eb6-408d-f04f-c840bf25d6ca"},"source":["train_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'backpack'\n","  print(prediction)\n","\n","elif result[0][1] == 2:\n","  prediction = 'footwear'\n","  print(prediction)\n","\n","elif result[0][2] == 3:\n","  prediction = 'glasses'\n","  print(prediction)\n","\n","else:\n","  prediction = 'watch'\n","  print(prediction)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["watch\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U4yqEMGOoBtR","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}